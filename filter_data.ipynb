{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa18c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 177582\n",
      "Rows in [1.7, 2.15]: 146364  -> keeping 87818 (60%)\n",
      "New total rows: 119036\n",
      "Wrote: merged_output_cut.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- knobs you can edit ---\n",
    "IN_PATH   = \"merged_output.csv\"     # input file\n",
    "OUT_PATH  = \"merged_output_cut.csv\" # output file\n",
    "COL       = \"LogGFP\"                # column to filter on\n",
    "LOW, HIGH = 1.70, 2.15              # range to trim (inclusive)\n",
    "KEEP_FRAC = 0.60                    # keep 70% (drop 30%)\n",
    "SEED      = 123                     # reproducible randomness\n",
    "# ---------------------------\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "# Make a clean numeric series for the target column\n",
    "x = pd.to_numeric(df[COL], errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Mask for rows inside the target range (inclusive)\n",
    "mask_range = x.between(LOW, HIGH, inclusive=\"both\")\n",
    "\n",
    "# Rows to keep inside the range: sample without replacement\n",
    "idx_in = df.index[mask_range]\n",
    "n_in = len(idx_in)\n",
    "n_keep = int(round(n_in * KEEP_FRAC))\n",
    "\n",
    "if n_in == 0:\n",
    "    print(f\"No rows in [{LOW}, {HIGH}] — nothing to cut.\")\n",
    "    trimmed = df.copy()\n",
    "else:\n",
    "    keep_idx_in = set(rng.choice(idx_in, size=n_keep, replace=False))\n",
    "    # Build final keep mask: keep all outside the range + sampled inside\n",
    "    keep_mask = (~mask_range) | df.index.to_series().isin(keep_idx_in)\n",
    "    trimmed = df.loc[keep_mask].copy()\n",
    "\n",
    "# Report\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Rows in [{LOW}, {HIGH}]: {n_in}  -> keeping {n_keep} ({KEEP_FRAC*100:.0f}%)\")\n",
    "print(f\"New total rows: {len(trimmed)}\")\n",
    "\n",
    "# Save\n",
    "trimmed.to_csv(OUT_PATH, index=False)\n",
    "print(f\"Wrote: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b1d15",
   "metadata": {},
   "source": [
    "Filter in bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc4ed1",
   "metadata": {},
   "source": [
    "trying it more simpel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4b15a3",
   "metadata": {},
   "source": [
    "now with kutting the middle and the expremes duplicating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7b459",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c368021",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbc4e364",
   "metadata": {},
   "source": [
    "with more to the extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ae31b",
   "metadata": {},
   "source": [
    "comapre the differnt contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "644583dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original per-bin counts: {0: 41, 1: 68, 2: 109, 3: 206, 4: 473, 5: 849, 6: 1259, 7: 1860, 8: 2521, 9: 3628, 10: 5150, 11: 7174, 12: 10046, 13: 15408, 14: 26406, 15: 19690, 16: 17572, 17: 17412, 18: 17405, 19: 12357, 20: 5500, 21: 2442, 22: 1183, 23: 915, 24: 1115, 25: 1342, 26: 1581, 27: 776, 28: 877, 29: 853, 30: 746, 31: 292, 32: 37, 33: 43, 34: 33, 35: 25, 36: 9, 37: 8, 38: 4, 39: 6}\n",
      "Balanced per-bin counts: {0: 410, 1: 612, 2: 436, 3: 412, 4: 615, 5: 1104, 6: 1259, 7: 1860, 8: 2521, 9: 3628, 10: 3450, 11: 3730, 12: 4219, 13: 4622, 14: 5281, 15: 5907, 16: 5623, 17: 6094, 18: 6266, 19: 6178, 20: 5500, 21: 4151, 22: 2011, 23: 4118, 24: 2230, 25: 1745, 26: 1739, 27: 1707, 28: 1754, 29: 2730, 30: 2909, 31: 1168, 32: 555, 33: 258, 34: 231, 35: 250, 36: 153, 37: 152, 38: 156, 39: 162}\n",
      "\n",
      "Targets per bin (after scaling):\n",
      "  bin 00: cur=41, factor=10, target=410\n",
      "  bin 01: cur=68, factor=9, target=612\n",
      "  bin 02: cur=109, factor=4, target=436\n",
      "  bin 03: cur=206, factor=2, target=412\n",
      "  bin 04: cur=473, factor=1.3, target=615\n",
      "  bin 05: cur=849, factor=1.3, target=1104\n",
      "  bin 06: cur=1259, factor=1, target=1259\n",
      "  bin 07: cur=1860, factor=1, target=1860\n",
      "  bin 08: cur=2521, factor=1, target=2521\n",
      "  bin 09: cur=3628, factor=1, target=3628\n",
      "  bin 10: cur=5150, factor=0.67, target=3450\n",
      "  bin 11: cur=7174, factor=0.52, target=3730\n",
      "  bin 12: cur=10046, factor=0.42, target=4219\n",
      "  bin 13: cur=15408, factor=0.3, target=4622\n",
      "  bin 14: cur=26406, factor=0.2, target=5281\n",
      "  bin 15: cur=19690, factor=0.3, target=5907\n",
      "  bin 16: cur=17572, factor=0.32, target=5623\n",
      "  bin 17: cur=17412, factor=0.35, target=6094\n",
      "  bin 18: cur=17405, factor=0.36, target=6266\n",
      "  bin 19: cur=12357, factor=0.5, target=6178\n",
      "  bin 20: cur=5500, factor=1, target=5500\n",
      "  bin 21: cur=2442, factor=1.7, target=4151\n",
      "  bin 22: cur=1183, factor=1.7, target=2011\n",
      "  bin 23: cur=915, factor=4.5, target=4118\n",
      "  bin 24: cur=1115, factor=2, target=2230\n",
      "  bin 25: cur=1342, factor=1.3, target=1745\n",
      "  bin 26: cur=1581, factor=1.1, target=1739\n",
      "  bin 27: cur=776, factor=2.2, target=1707\n",
      "  bin 28: cur=877, factor=2, target=1754\n",
      "  bin 29: cur=853, factor=3.2, target=2730\n",
      "  bin 30: cur=746, factor=3.9, target=2909\n",
      "  bin 31: cur=292, factor=4, target=1168\n",
      "  bin 32: cur=37, factor=15, target=555\n",
      "  bin 33: cur=43, factor=6, target=258\n",
      "  bin 34: cur=33, factor=7, target=231\n",
      "  bin 35: cur=25, factor=10, target=250\n",
      "  bin 36: cur=9, factor=17, target=153\n",
      "  bin 37: cur=8, factor=19, target=152\n",
      "  bin 38: cur=4, factor=39, target=156\n",
      "  bin 39: cur=6, factor=27, target=162\n",
      "\n",
      "Wrote merged_output_balanced_2.csv and bin_edges.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===================== knobs =====================\n",
    "IN_PATH   = \"merged_output.csv\"\n",
    "OUT_PATH  = \"merged_output_balanced_2.csv\"\n",
    "COL       = \"LogGFP\"\n",
    "LOWER     = 1.2\n",
    "NBINS     = 40\n",
    "\n",
    "SEED      = 123\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# Per-bin scale factors (0-based bin index):\n",
    "#   factor > 1.0  -> oversample with replacement to target size\n",
    "#   factor = 1.0  -> keep as-is\n",
    "#   factor < 1.0  -> downsample WITHOUT replacement to target size\n",
    "SCALE_MAP = {\n",
    "    0: 10.0,\n",
    "    1: 9.0,\n",
    "    2: 4.0,\n",
    "    3: 2.0,\n",
    "    4: 1.3, \n",
    "    5: 1.3,# downsample bin 5 to 70%\n",
    "    6: 1.0, \n",
    "    7: 1.0,\n",
    "    8: 1.0,\n",
    "    9: 1.0,\n",
    "    10:0.67,\n",
    "    11:0.52,\n",
    "    12:0.42,\n",
    "    13: 0.30,\n",
    "    14: 0.20,\n",
    "    15: 0.30,\n",
    "    16: 0.32,\n",
    "    17: 0.35,\n",
    "    18: 0.36,\n",
    "    19: 0.37,\n",
    "    \n",
    "    \n",
    "    19: 0.50,\n",
    "    20: 1.0,\n",
    "    21:1.7,\n",
    "    22: 1.7,\n",
    "    23: 4.5,\n",
    "    24:2.0,\n",
    "    25:1.3,\n",
    "        26:1.1,\n",
    "            27:2.2,\n",
    "                28:2.0,\n",
    "                    29:3.2,\n",
    "                    30:3.9,\n",
    "                        31: 4,\n",
    "                            32:15,\n",
    "                                33:6.0,\n",
    "                                    34:7,\n",
    "                                        35:10,\n",
    "                                            36:17,\n",
    "                                                37:19,\n",
    "                                                    38:39,\n",
    "                                                        \n",
    "                                                        39:27,\n",
    "                        \n",
    "}\n",
    "\n",
    "# Optional: range trimming BEFORE bin scaling (list of tuples)\n",
    "# Each tuple: (low, high, keep_frac). Example keeps 70% in [1.75, 2.10].\n",
    "RANGE_TRIMS = [\n",
    "    # (1.75, 2.10, 0.70),\n",
    "]\n",
    "\n",
    "# =================================================\n",
    "\n",
    "# --- load & filter to LOWER like in your pipeline ---\n",
    "df = pd.read_csv(IN_PATH)\n",
    "x = pd.to_numeric(df[COL], errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "df = df.loc[x.notna() & (x >= LOWER)].copy()\n",
    "\n",
    "# --- optional range-based trims (no leakage; removes rows only) ---\n",
    "for (low, high, keep_frac) in RANGE_TRIMS:\n",
    "    mask = df[COL].between(low, high, inclusive=\"both\")\n",
    "    idx_in = df.index[mask]\n",
    "    n_in = len(idx_in)\n",
    "    k = int(round(n_in * keep_frac))\n",
    "    if n_in and 0 <= k < n_in:\n",
    "        keep_idx = set(rng.choice(idx_in, size=k, replace=False))\n",
    "        keep_mask = (~mask) | df.index.to_series().isin(keep_idx)\n",
    "        df = df.loc[keep_mask].copy()\n",
    "        print(f\"Trimmed [{low}, {high}] to {keep_frac:.0%}: kept {k}/{n_in}\")\n",
    "\n",
    "# --- fixed edges (LOWER..max), with nextafter padding like before ---\n",
    "xmax  = float(df[COL].max())\n",
    "edges = np.linspace(LOWER, xmax, NBINS + 1)\n",
    "edges[0]  = np.nextafter(edges[0],  -np.inf)\n",
    "edges[-1] = np.nextafter(edges[-1],  np.inf)\n",
    "\n",
    "# --- assign bins with right-inclusive semantics (pd.cut) ---\n",
    "b = pd.cut(df[COL], bins=edges, right=True, include_lowest=True, labels=False)\n",
    "if b.isna().any():\n",
    "    df = df.loc[b.notna()].copy()\n",
    "    b  = b.loc[b.notna()]\n",
    "df[\"_bin\"] = b.astype(int)\n",
    "\n",
    "# --- diagnostics: original counts ---\n",
    "orig_counts = df[\"_bin\"].value_counts().sort_index()\n",
    "print(\"Original per-bin counts:\", orig_counts.to_dict())\n",
    "\n",
    "# --- per-bin scaling (now supports downsampling when factor < 1) ---\n",
    "scaled_parts = []\n",
    "targets_report = []\n",
    "\n",
    "for bval, block in df.groupby(\"_bin\"):\n",
    "    factor = float(SCALE_MAP.get(bval, 1.0))\n",
    "    cur = len(block)\n",
    "    target = int(round(cur * factor))\n",
    "    targets_report.append((bval, cur, factor, target))\n",
    "\n",
    "    if target <= 0:\n",
    "        # drop bin entirely if requested\n",
    "        continue\n",
    "    if target == cur:\n",
    "        scaled_parts.append(block)\n",
    "    elif target > cur:\n",
    "        # oversample WITH replacement\n",
    "        idx = rng.choice(block.index, size=target, replace=True)\n",
    "        scaled_parts.append(block.loc[idx])\n",
    "    else:\n",
    "        # downsample WITHOUT replacement\n",
    "        idx = rng.choice(block.index, size=target, replace=False)\n",
    "        scaled_parts.append(block.loc[idx])\n",
    "\n",
    "balanced = pd.concat(scaled_parts, ignore_index=True)\n",
    "\n",
    "# --- verify with same edges & show counts ---\n",
    "final_bins = pd.cut(balanced[COL], bins=edges, right=True, include_lowest=True, labels=False)\n",
    "balanced[\"_bin\"] = final_bins.astype(int)\n",
    "\n",
    "bal_counts = balanced[\"_bin\"].value_counts().sort_index()\n",
    "print(\"Balanced per-bin counts:\", bal_counts.to_dict())\n",
    "\n",
    "print(\"\\nTargets per bin (after scaling):\")\n",
    "for bval, cur, factor, target in sorted(targets_report):\n",
    "    print(f\"  bin {bval:02d}: cur={cur}, factor={factor:.3g}, target={target}\")\n",
    "\n",
    "# --- save outputs ---\n",
    "balanced.drop(columns=[\"_bin\"]).to_csv(OUT_PATH, index=False)\n",
    "np.save(\"bin_edges.npy\", edges)\n",
    "print(f\"\\nWrote {OUT_PATH} and bin_edges.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9418ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Bin  Count\n",
      "  [1.2, 1.295]    654\n",
      "[1.295, 1.389]   1260\n",
      "[1.389, 1.484]   3966\n",
      "[1.484, 1.579]   6238\n",
      "[1.579, 1.674]   7994\n",
      "[1.674, 1.768]   7394\n",
      "[1.768, 1.863]  15272\n",
      "[1.863, 1.958]  36877\n",
      "[1.958, 2.052]  34984\n",
      "[2.052, 2.147]  59524\n",
      "[2.147, 2.242]  15884\n",
      "[2.242, 2.337]   6294\n",
      "[2.337, 2.431]  12285\n",
      "[2.431, 2.526]  16499\n",
      "[2.526, 2.621]  13840\n",
      "[2.621, 2.715]   1038\n",
      " [2.715, 2.81]     80\n",
      " [2.81, 2.905]     58\n",
      "    [2.905, 3]     17\n",
      "    [3, 3.094]     10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fg/n7z04rk97lq4m1gks430p30c0000gn/T/ipykernel_10988/1609385777.py:59: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# --- One-file distribution plot (uses same binning rules as your balancer) ---\n",
    "import os, time\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==== CONFIG: point to the file you want to visualize ====\n",
    "CSV_PATH  = \"merged_output_balanced.csv\"   # <- your current file\n",
    "COL       = \"LogGFP\"\n",
    "LOWER     = 1.2\n",
    "NBINS     = 20\n",
    "EDGES_NPY = \"bin_edges.npy\"                # will use if present\n",
    "SAVE_PNG  = False                          # set True to also save a PNG\n",
    "# =========================================================\n",
    "\n",
    "def make_edges_from_file(values, lower, nbins):\n",
    "    vmax = float(values.max())\n",
    "    edges = np.linspace(lower, vmax, nbins + 1)\n",
    "    edges[0]  = np.nextafter(edges[0],  -np.inf)  # swallow the exact lower bound\n",
    "    edges[-1] = np.nextafter(edges[-1],  np.inf)  # swallow the exact upper bound\n",
    "    return edges\n",
    "\n",
    "# 1) Load & filter to LOWER exactly like the balancer\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "x  = pd.to_numeric(df[COL], errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "df = df.loc[x.notna() & (x >= LOWER)].copy()\n",
    "xv = df[COL].astype(float).values\n",
    "assert len(xv) > 0, f\"No rows >= {LOWER} in {CSV_PATH}\"\n",
    "\n",
    "# 2) Load edges if available; otherwise build them the same way\n",
    "if os.path.exists(EDGES_NPY):\n",
    "    edges = np.load(EDGES_NPY)\n",
    "    # sanity: if edges don’t match current file domain, rebuild them\n",
    "    if (edges[0] > LOWER*0.9999) or (edges[-1] < xv.max()*0.9999) or (len(edges) != NBINS+1):\n",
    "        edges = make_edges_from_file(xv, LOWER, NBINS)\n",
    "else:\n",
    "    edges = make_edges_from_file(xv, LOWER, NBINS)\n",
    "\n",
    "nb = len(edges) - 1\n",
    "\n",
    "# 3) Assign bins with the SAME rule: right-inclusive, include_lowest\n",
    "b = pd.cut(df[COL], bins=edges, right=True, include_lowest=True, labels=False)\n",
    "b = b.astype(int)  # no NaNs expected thanks to nextafter\n",
    "\n",
    "# 4) Counts and labels\n",
    "counts = b.value_counts().sort_index()\n",
    "# ensure every bin is present\n",
    "counts = counts.reindex(range(nb), fill_value=0)\n",
    "\n",
    "labels  = [f\"[{edges[i]:.4g}, {edges[i+1]:.4g}]\" for i in range(nb)]\n",
    "widths  = edges[1:] - edges[:-1]\n",
    "centers = (edges[1:] + edges[:-1]) / 2.0\n",
    "\n",
    "# 5) Plot bars at the true bin positions/widths\n",
    "plt.figure(figsize=(8,4.5))\n",
    "plt.bar(centers, counts.values, width=widths*0.9, alpha=0.8, edgecolor=\"black\", linewidth=0.4)\n",
    "plt.xlabel(COL); plt.ylabel(\"Count\")\n",
    "plt.title(f\"Distribution of {os.path.basename(CSV_PATH)}\\n({nb} fixed bins from {edges[0]:.3g}, right-inclusive)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6) Also print a neat count table\n",
    "counts_df = pd.DataFrame({\"Bin\": labels, \"Count\": counts.values})\n",
    "print(counts_df.to_string(index=False))\n",
    "\n",
    "# 7) Optional: save PNG\n",
    "if SAVE_PNG:\n",
    "    out_name = f\"dist_{nb}bins_from{float(edges[0]):.2f}_{int(time.time())}.png\"\n",
    "\n",
    "    _ = plt.figure()  # not used; kept for safety\n",
    "    # replot quick for saving (or reuse the previous fig if you prefer)\n",
    "    plt.close(_)  # close the noop\n",
    "    # you can also save the previous figure by grabbing it via plt.gcf()\n",
    "    plt.gcf().savefig(out_name, dpi=200, bbox_inches=\"tight\")\n",
    "    print(\"Saved:\", os.path.abspath(out_name))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
